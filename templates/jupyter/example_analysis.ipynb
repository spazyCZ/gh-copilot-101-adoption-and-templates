{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66355529",
   "metadata": {},
   "source": [
    "# Example Data Analysis with Standardized Visualization\n",
    "\n",
    "This notebook demonstrates best practices for data analysis and visualization using seaborn and matplotlib.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Package Installation](#installation)\n",
    "2. [Setup and Imports](#setup)\n",
    "3. [Data Loading](#loading)\n",
    "4. [Data Summary and Exploration](#summary)\n",
    "5. [Data Visualization](#visualization)\n",
    "   - Bar Plot\n",
    "   - Line Plot\n",
    "   - Scatter Plot\n",
    "6. [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972293d6",
   "metadata": {},
   "source": [
    "<a id=\"installation\"></a>\n",
    "## 1. Package Installation\n",
    "\n",
    "First, let's ensure all required packages are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (recommended for Jupyter)\n",
    "# This cell ensures all dependencies are available in the environment.\n",
    "# If running in a restricted environment, comment out the following line.\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45c7df",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 2. Setup and Imports\n",
    "\n",
    "Import necessary libraries and set up logging. We use seaborn and matplotlib for standardized visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from typing import Any, Dict, List, Tuple, Optional, Union\n",
    "\n",
    "# Import custom utility functions\n",
    "from src.utils import summarize_data\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Setting up analysis environment\")\n",
    "\n",
    "# Set default plot style for consistent visualizations\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Set colorblind-friendly palette for accessibility\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Configure matplotlib defaults for consistency\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.dpi': 100\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d2e5a",
   "metadata": {},
   "source": [
    "<a id=\"loading\"></a>\n",
    "## 3. Load Example Data\n",
    "\n",
    "We'll use the tips dataset from seaborn, which contains information about tips in a restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tips dataset from seaborn\n",
    "df: pd.DataFrame = sns.load_dataset('tips')\n",
    "\n",
    "# Log information about the loaded dataset\n",
    "logger.info(f'Data loaded: {df.shape[0]} rows and {df.shape[1]} columns')\n",
    "\n",
    "# Validate data was loaded correctly\n",
    "assert df.shape[0] > 0, \"Dataset is empty, no rows were loaded\"\n",
    "assert df.shape[1] > 0, \"Dataset has no columns\"\n",
    "assert 'tip' in df.columns, \"Expected 'tip' column not found in dataset\"\n",
    "assert 'total_bill' in df.columns, \"Expected 'total_bill' column not found in dataset\"\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904f9c7",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 4. Data Summary and Exploration\n",
    "\n",
    "Let's explore the dataset to understand its structure and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ee6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_data_quality(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform a comprehensive data quality assessment on a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df: The DataFrame to assess\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary with data quality metrics\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary\n",
    "    quality_metrics: Dict[str, Any] = {}\n",
    "    \n",
    "    # 1. Missing values\n",
    "    quality_metrics['missing_values'] = df.isnull().sum().to_dict()\n",
    "    quality_metrics['missing_percentage'] = (df.isnull().sum() / len(df) * 100).to_dict()\n",
    "    \n",
    "    # 2. Duplicate rows\n",
    "    quality_metrics['duplicate_rows'] = df.duplicated().sum()\n",
    "    quality_metrics['duplicate_percentage'] = (df.duplicated().sum() / len(df) * 100)\n",
    "    \n",
    "    # 3. Basic statistics for numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    quality_metrics['numerical_stats'] = {}\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        quality_metrics['numerical_stats'][col] = {\n",
    "            'min': df[col].min(),\n",
    "            'max': df[col].max(),\n",
    "            'mean': df[col].mean(),\n",
    "            'median': df[col].median(),\n",
    "            'std': df[col].std(),\n",
    "            'zeros': (df[col] == 0).sum(),\n",
    "            'negatives': (df[col] < 0).sum() if df[col].min() < 0 else 0\n",
    "        }\n",
    "    \n",
    "    # 4. Categorical column analysis\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    quality_metrics['categorical_stats'] = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        quality_metrics['categorical_stats'][col] = {\n",
    "            'unique_values': df[col].nunique(),\n",
    "            'most_common': df[col].value_counts().nlargest(3).to_dict()\n",
    "        }\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "# Run the data quality assessment\n",
    "quality_results = assess_data_quality(df)\n",
    "\n",
    "# Display the results in a readable format\n",
    "print(\"\\nData Quality Assessment Summary:\")\n",
    "print(f\"Total rows: {df.shape[0]}, Total columns: {df.shape[1]}\")\n",
    "\n",
    "if sum(quality_results['missing_values'].values()) == 0:\n",
    "    print(\"✓ No missing values detected\")\n",
    "else:\n",
    "    print(\"⚠ Missing values detected\")\n",
    "    for col, count in quality_results['missing_values'].items():\n",
    "        if count > 0:\n",
    "            print(f\"  - {col}: {count} missing ({quality_results['missing_percentage'][col]:.2f}%)\")\n",
    "\n",
    "if quality_results['duplicate_rows'] == 0:\n",
    "    print(\"✓ No duplicate rows detected\")\n",
    "else:\n",
    "    print(f\"⚠ {quality_results['duplicate_rows']} duplicate rows detected ({quality_results['duplicate_percentage']:.2f}%)\")\n",
    "\n",
    "# Check for potential data issues\n",
    "print(\"\\nPotential Data Issues:\")\n",
    "issues_found = False\n",
    "\n",
    "for col, stats in quality_results['numerical_stats'].items():\n",
    "    if stats['negatives'] > 0 and col not in ['temperature', 'change', 'difference']:\n",
    "        print(f\"⚠ {stats['negatives']} negative values found in '{col}' column\")\n",
    "        issues_found = True\n",
    "        \n",
    "    if stats['zeros'] > 0 and col in ['total_bill', 'tip']:\n",
    "        print(f\"⚠ {stats['zeros']} zero values found in '{col}' column\")\n",
    "        issues_found = True\n",
    "        \n",
    "    # Check for potential outliers (values > 3 standard deviations)\n",
    "    upper_bound = stats['mean'] + 3 * stats['std']\n",
    "    lower_bound = stats['mean'] - 3 * stats['std']\n",
    "    outliers_high = (df[col] > upper_bound).sum()\n",
    "    outliers_low = (df[col] < lower_bound).sum()\n",
    "    \n",
    "    if outliers_high + outliers_low > 0:\n",
    "        print(f\"⚠ {outliers_high + outliers_low} potential outliers found in '{col}' column\")\n",
    "        issues_found = True\n",
    "\n",
    "if not issues_found:\n",
    "    print(\"✓ No obvious data issues detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our utility function to summarize the data\n",
    "summarize_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the summarize_data utility function\n",
    "try:\n",
    "    # First, assert the function exists and is callable\n",
    "    assert callable(summarize_data), \"summarize_data function is not callable\"\n",
    "    \n",
    "    # Call the function\n",
    "    summarize_data(df)\n",
    "    \n",
    "    logger.info(\"summarize_data function executed successfully\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error testing summarize_data function: {e}\")\n",
    "    \n",
    "    # Create a simple implementation if the imported one fails\n",
    "    def local_summarize_data(df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Print summary statistics for a DataFrame.\n",
    "        :param df: pandas DataFrame\n",
    "        \"\"\"\n",
    "        logger.info(f\"DataFrame shape: {df.shape}\")\n",
    "        display(df.head())\n",
    "        display(df.describe())\n",
    "    \n",
    "    logger.info(\"Using local implementation of summarize_data\")\n",
    "    local_summarize_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "deficit: pd.Series = df.isnull().sum()\n",
    "\n",
    "# Use logging instead of print statements\n",
    "logger.info(\"Missing values check complete\")\n",
    "\n",
    "# Add assertions to validate data quality\n",
    "if deficit.sum() > 0:\n",
    "    logger.warning(f\"Found {deficit.sum()} missing values\")\n",
    "    display(deficit[deficit > 0])\n",
    "    \n",
    "    # Add an assertion that would fail if there are too many missing values (>10% of data)\n",
    "    total_cells: int = df.shape[0] * df.shape[1]\n",
    "    missing_percentage: float = (deficit.sum() / total_cells) * 100\n",
    "    assert missing_percentage < 10, f\"Too many missing values: {missing_percentage:.2f}% of data is missing\"\n",
    "else:\n",
    "    logger.info(\"No missing values found\")\n",
    "    assert deficit.sum() == 0, \"Missing values detected despite sum check\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e808c",
   "metadata": {},
   "source": [
    "### Data Distribution\n",
    "\n",
    "Let's examine the distribution of numerical columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57840504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlation_heatmap(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Create a heatmap visualization of correlations between numeric variables.\n",
    "    \n",
    "    Parameters:\n",
    "        df: DataFrame with numeric columns to analyze\n",
    "    \"\"\"\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Create mask for upper triangle\n",
    "    heatmap = sns.heatmap(\n",
    "        corr_matrix, \n",
    "        annot=True,        # Show correlation values\n",
    "        fmt=\".2f\",         # Format as 2 decimal places\n",
    "        cmap=\"coolwarm\",   # Color map (red for negative, blue for positive)\n",
    "        mask=mask,         # Apply mask to hide upper triangle\n",
    "        linewidths=0.5,    # Width of cell borders\n",
    "        cbar_kws={\"shrink\": 0.8}  # Colorbar settings\n",
    "    )\n",
    "    plt.title('Correlation Matrix of Numerical Variables', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print strongest correlations\n",
    "    # Get the upper triangle of the correlation matrix (excluding diagonal)\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find the top 3 strongest correlations\n",
    "    strongest_correlations = upper.abs().stack().nlargest(3)\n",
    "    print(\"Strongest correlations:\")\n",
    "    for i, (idx, val) in enumerate(strongest_correlations.items(), 1):\n",
    "        print(f\"{i}. {idx[0]} — {idx[1]}: {val:.3f}\")\n",
    "\n",
    "# Create the correlation heatmap\n",
    "create_correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc63859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distribution_plots(dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Create histogram plots for all numerical columns in the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe: The pandas DataFrame containing the data to visualize\n",
    "        \n",
    "    Returns:\n",
    "        None - displays the plots directly\n",
    "    \"\"\"\n",
    "    # Get list of numerical columns\n",
    "    numerical_cols: List[str] = dataframe.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    \n",
    "    # Create a figure with subplots for each numerical column\n",
    "    fig, axes = plt.subplots(len(numerical_cols), 1, figsize=(10, 3*len(numerical_cols)))\n",
    "    \n",
    "    # Generate histogram with KDE for each numerical column\n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        sns.histplot(data=dataframe, x=col, kde=True, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        \n",
    "        # Add mean and median lines\n",
    "        mean_val: float = dataframe[col].mean()\n",
    "        median_val: float = dataframe[col].median()\n",
    "        axes[i].axvline(mean_val, color='r', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "        axes[i].axvline(median_val, color='g', linestyle='-.', label=f'Median: {median_val:.2f}')\n",
    "        axes[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Create the distribution plots\n",
    "create_distribution_plots(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82e289",
   "metadata": {},
   "source": [
    "<a id=\"visualization\"></a>\n",
    "## 5. Data Visualization\n",
    "\n",
    "We'll create several visualizations to explore relationships in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464375b0",
   "metadata": {},
   "source": [
    "### Bar Plot: Average Tip by Day\n",
    "\n",
    "This visualization shows the average tip amount for each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d5a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_plot(data: pd.DataFrame, x_col: str, y_col: str, title: str, \n",
    "                   order: Optional[List[str]] = None, palette: str = 'deep') -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a standardized bar plot with error bars and value labels.\n",
    "    \n",
    "    Parameters:\n",
    "        data: The pandas DataFrame containing the data\n",
    "        x_col: The column name for the x-axis categories\n",
    "        y_col: The column name for the y-axis values\n",
    "        title: The title for the plot\n",
    "        order: Optional list to specify the order of categories\n",
    "        palette: The color palette to use\n",
    "        \n",
    "    Returns:\n",
    "        The matplotlib Figure object\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(data=data, x=x_col, y=y_col, ci='sd', palette=palette, order=order)\n",
    "    \n",
    "    # Add mean values on top of each bar\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width()/2, height + 0.1, f'${height:.2f}', ha='center')\n",
    "    \n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.ylabel(f'{y_col} Amount ($)', fontsize=12)\n",
    "    plt.xlabel(x_col, fontsize=12)\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df70c965",
   "metadata": {},
   "source": [
    "### Tip Percentage Analysis\n",
    "\n",
    "Let's analyze the tip as a percentage of the total bill to normalize across different bill amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tip percentage\n",
    "df['tip_pct'] = (df['tip'] / df['total_bill']) * 100\n",
    "\n",
    "# Define a function to create tip percentage visualization\n",
    "def analyze_tip_percentage(data: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Analyze and visualize tip percentages across different factors.\n",
    "    \n",
    "    Parameters:\n",
    "        data: DataFrame with tip_pct column\n",
    "    \"\"\"\n",
    "    # Create figure for tip percentage by various factors\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Tip percentage by day\n",
    "    sns.boxplot(data=data, x='day', y='tip_pct', ax=axes[0, 0], order=['Thur', 'Fri', 'Sat', 'Sun'])\n",
    "    axes[0, 0].set_title('Tip Percentage by Day')\n",
    "    axes[0, 0].set_ylabel('Tip %')\n",
    "    \n",
    "    # 2. Tip percentage by gender\n",
    "    sns.boxplot(data=data, x='sex', y='tip_pct', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Tip Percentage by Gender')\n",
    "    axes[0, 1].set_ylabel('Tip %')\n",
    "    \n",
    "    # 3. Tip percentage by smoking status\n",
    "    sns.boxplot(data=data, x='smoker', y='tip_pct', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Tip Percentage by Smoker Status')\n",
    "    axes[1, 0].set_ylabel('Tip %')\n",
    "    \n",
    "    # 4. Tip percentage by time\n",
    "    sns.boxplot(data=data, x='time', y='tip_pct', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Tip Percentage by Time')\n",
    "    axes[1, 1].set_ylabel('Tip %')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate average tip percentages by groups and log them\n",
    "    logger.info(\"Average tip percentages by group:\")\n",
    "    for factor in ['day', 'time', 'sex', 'smoker']:\n",
    "        avg_by_group = data.groupby(factor)['tip_pct'].mean()\n",
    "        display(pd.DataFrame(avg_by_group).rename(columns={'tip_pct': f'Avg Tip % by {factor}'}))\n",
    "        \n",
    "# Run the tip percentage analysis\n",
    "analyze_tip_percentage(df)\n",
    "\n",
    "# Validate the tip percentages\n",
    "assert df['tip_pct'].max() < 100, \"Tip percentage should not exceed 100%\"\n",
    "assert df['tip_pct'].min() >= 0, \"Tip percentage should not be negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=df, x='day', y='tip', ci='sd', palette='deep', order=['Thur', 'Fri', 'Sat', 'Sun'])\n",
    "\n",
    "# Add mean tip values on top of each bar\n",
    "for i, p in enumerate(ax.patches):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2, height + 0.1, f'${height:.2f}', ha='center')\n",
    "\n",
    "plt.title('Average Tip by Day of Week', fontsize=16)\n",
    "plt.ylabel('Tip Amount ($)', fontsize=12)\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7b050",
   "metadata": {},
   "source": [
    "### Line Plot: Average Total Bill by Day and Time\n",
    "\n",
    "This visualization shows how the average bill varies by day and time (lunch vs dinner).\n",
    "\n",
    "# Create bar plot with days in correct order\n",
    "day_order: List[str] = ['Thur', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "# Use our utility function for consistent styling\n",
    "fig = create_bar_plot(\n",
    "    data=df,\n",
    "    x_col='day',\n",
    "    y_col='tip',\n",
    "    title='Average Tip by Day of Week',\n",
    "    order=day_order\n",
    ")\n",
    "\n",
    "# Add annotations to highlight weekend vs weekday difference\n",
    "weekday_avg: float = df[df['day'].isin(['Thur', 'Fri'])]['tip'].mean()\n",
    "weekend_avg: float = df[df['day'].isin(['Sat', 'Sun'])]['tip'].mean()\n",
    "diff_pct: float = ((weekend_avg - weekday_avg) / weekday_avg) * 100\n",
    "\n",
    "# Add annotation to highlight the weekend vs weekday difference\n",
    "plt.annotate(\n",
    "    f'Weekend tips are {diff_pct:.1f}% higher than weekdays', \n",
    "    xy=(0.5, 0.9), \n",
    "    xycoords='axes fraction',\n",
    "    bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "    ha='center'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Perform statistical verification with assertions\n",
    "assert weekend_avg > weekday_avg, \"Weekend tips should be higher than weekday tips\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12822a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average bill by day and time\n",
    "avg_bill = df.groupby(['day', 'time'])['total_bill'].mean().reset_index()\n",
    "avg_bill['day'] = pd.Categorical(avg_bill['day'], categories=['Thur', 'Fri', 'Sat', 'Sun'], ordered=True)\n",
    "avg_bill = avg_bill.sort_values('day')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=avg_bill, x='day', y='total_bill', hue='time', marker='o', markersize=10)\n",
    "plt.title('Average Total Bill by Day and Time', fontsize=16)\n",
    "plt.ylabel('Average Total Bill ($)', fontsize=12)\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941e837",
   "metadata": {},
   "source": [
    "### Scatter Plot: Total Bill vs. Tip with Regression Line\n",
    "\n",
    "This visualization shows the relationship between total bill and tip amount, colored by gender and with different markers for smokers and non-smokers.\n",
    "\n",
    "### Line Plot: Average Total Bill by Day and Time\n",
    "\n",
    "This visualization shows the average total bill grouped by day and time, with annotations for each point and warnings for missing combinations.\n",
    "\n",
    "```python\n",
    "def prepare_day_time_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares data for day/time analysis by grouping and sorting appropriately.\n",
    "    \n",
    "    Parameters:\n",
    "        df: Input DataFrame with day and time columns\n",
    "        \n",
    "    Returns:\n",
    "        A grouped and sorted DataFrame with average bills by day and time\n",
    "    \"\"\"\n",
    "    # Calculate average bill by day and time\n",
    "    grouped_data: pd.DataFrame = df.groupby(['day', 'time'])['total_bill'].mean().reset_index()\n",
    "    \n",
    "    # Ensure days are in correct order (Thursday through Sunday)\n",
    "    grouped_data['day'] = pd.Categorical(\n",
    "        grouped_data['day'], \n",
    "        categories=['Thur', 'Fri', 'Sat', 'Sun'], \n",
    "        ordered=True\n",
    "    )\n",
    "    \n",
    "    # Sort by the ordered day column\n",
    "    return grouped_data.sort_values('day')\n",
    "\n",
    "# Get the prepared data\n",
    "avg_bill: pd.DataFrame = prepare_day_time_data(df)\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=avg_bill, \n",
    "    x='day', \n",
    "    y='total_bill', \n",
    "    hue='time', \n",
    "    marker='o', \n",
    "    markersize=10,\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Average Total Bill by Day and Time', fontsize=16)\n",
    "plt.ylabel('Average Total Bill ($)', fontsize=12)\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value annotations on each point\n",
    "for day in ['Thur', 'Fri', 'Sat', 'Sun']:\n",
    "    for time in ['Lunch', 'Dinner']:\n",
    "        try:\n",
    "            value = avg_bill[(avg_bill['day'] == day) & (avg_bill['time'] == time)]['total_bill'].values[0]\n",
    "            plt.annotate(\n",
    "                f'${value:.2f}',\n",
    "                xy=(day, value),\n",
    "                xytext=(0, 5),\n",
    "                textcoords='offset points',\n",
    "                ha='center'\n",
    "            )\n",
    "        except IndexError:\n",
    "            # Skip if combination doesn't exist\n",
    "            pass\n",
    "\n",
    "# Check for missing day/time combinations\n",
    "expected_combinations = 8  # 4 days x 2 times\n",
    "actual_combinations = len(avg_bill)\n",
    "if actual_combinations < expected_combinations:\n",
    "    logger.warning(f\"Missing {expected_combinations - actual_combinations} day/time combinations\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.scatterplot(data=df, x='total_bill', y='tip', hue='sex', style='smoker', palette='viridis')\n",
    "\n",
    "# Add regression line\n",
    "sns.regplot(data=df, x='total_bill', y='tip', scatter=False, ax=ax, line_kws={'color': 'red', 'linewidth': 2})\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "corr = df[['total_bill', 'tip']].corr().iloc[0, 1]\n",
    "plt.annotate(f'Correlation: {corr:.2f}', xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5))\n",
    "\n",
    "plt.title('Relationship Between Total Bill and Tip Amount', fontsize=16)\n",
    "plt.ylabel('Tip Amount ($)', fontsize=12)\n",
    "plt.xlabel('Total Bill ($)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9320c",
   "metadata": {},
   "source": [
    "<a id=\"conclusions\"></a>\n",
    "## 6. Conclusions\n",
    "\n",
    "From our analysis, we can draw several insights:, we can draw several meaningful insights:\n",
    "\n",
    "1. **Bill-Tip Correlation**: There is a statistically significant positive correlation between total bill amount and tip amount (r = 0.68), indicating that customers generally tip more when their bill is higher.\n",
    "\n",
    "2. **Temporal Patterns**: Weekend days (Saturday and Sunday) consistently show higher average tips than weekdays (Thursday and Friday), suggesting different tipping behavior during different parts of the week.\n",
    "\n",
    "3. **Meal Type Influence**: Dinner bills are typically higher than lunch bills across all days of the week, with the most substantial difference occurring on Saturdays.\n",
    "\n",
    "4. **Group Differences**: We observed some differences in tipping patterns between demographic groups, though further analysis would be needed to determine statistical significance of these differences.\n",
    "\n",
    "### Data Quality Assessment\n",
    "\n",
    "- The dataset is complete with no missing values\n",
    "- Sample size (n=244) is sufficient for basic statistical analysis\n",
    "- No extreme outliers were detected that would significantly distort our findings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"Regression p-value: {p_value:.4f}\")logger.info(f\"Linear regression: Tip = {slope:.2f} × Bill + {intercept:.2f}\")logger.info(f\"Correlation between total bill and tip: {correlation:.2f}\")# Log statistical findingsplt.show()plt.tight_layout()assert p_value < 0.05, \"Expected statistically significant relationship\"assert correlation > 0, \"Expected positive correlation between bill and tip\"# Add assertions to validate the analysisplt.grid(True, linestyle='--', alpha=0.7)plt.xlabel('Total Bill ($)', fontsize=12)plt.ylabel('Tip Amount ($)', fontsize=12)plt.title('Relationship Between Total Bill and Tip Amount', fontsize=16)# Customize the plot)    bbox=dict(boxstyle='round,pad=0.5', fc='lightgreen', alpha=0.5)    xycoords='axes fraction',     xy=(0.65, 0.85),     stat_text, plt.annotate(        stat_text += f\"{group}: ${group_stats.loc[group, 'mean']:.2f} avg tip ({avg_tip_pct[group]:.1f}%)\\n\"for group in group_stats.index:stat_text = \"Group Statistics:\\n\"# Add group statistics annotationavg_tip_pct = tip_percentage.groupby('sex')['tip_pct'].mean()tip_percentage = df.assign(tip_pct=df['tip']/df['total_bill']*100)group_stats = df.groupby('sex')['tip'].agg(['mean', 'median', 'count'])# Create group statistics)    bbox=dict(boxstyle='round,pad=0.5', fc='lightblue', alpha=0.5)    xycoords='axes fraction',     xy=(0.05, 0.87),     f'Tip = {slope:.2f} × Bill + {intercept:.2f}\\np-value: {p_value:.4f}', plt.annotate(slope, intercept, r_value, p_value, std_err = stats.linregress(df['total_bill'], df['tip'])from scipy import stats# Calculate slope and intercept of regression line# Add linear formula annotation)    bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5)    xycoords='axes fraction',     xy=(0.05, 0.95),     f'Correlation: {correlation:.2f}', plt.annotate(# Add statistics and insights to the plot)    style_col='smoker'    hue_col='sex',    y_col='tip',    x_col='total_bill',    df=df,fig, correlation = create_enhanced_scatter(# Create the enhanced scatter plot    return fig, corr        corr: float = df[[x_col, y_col]].corr().iloc[0, 1]    # Calculate and return correlation coefficient        )        line_kws={'color': 'red', 'linewidth': 2}        ax=ax,         scatter=False,         y=y_col,         x=x_col,         data=df,     sns.regplot(    # Add regression line for all data        )        alpha=0.7  # Semi-transparency        s=100,  # Larger point size        palette='viridis',        style=style_col,         hue=hue_col,         y=y_col,         x=x_col,         data=df,     ax = sns.scatterplot(    fig = plt.figure(figsize=(12, 8))    # Create figure and plot scatter points    \"\"\"        Figure object and correlation coefficient    Returns:                style_col: Column name for marker style grouping        hue_col: Column name for color grouping        y_col: Column name for y-axis values        x_col: Column name for x-axis values        df: DataFrame containing the data    Parameters:        Creates an enhanced scatter plot with regression line and correlation statistics.    \"\"\"                        hue_col: str, style_col: str) -> Tuple[plt.Figure, float]:def create_enhanced_scatter(df: pd.DataFrame, x_col: str, y_col: str, \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Note: This example notebook follows best practices for Jupyter notebooks including markdown documentation, type hints, proper cell organization, and standardized visualizations.*---5. Collect additional data on customer satisfaction to correlate with tipping behavior4. Conduct hypothesis tests to confirm if observed group differences are statistically significant3. Build a predictive model for tip amount based on other variables2. Investigate if party size affects tipping behavior1. Analyze the percentage tip rather than absolute amount to normalize for bill sizeTo further enhance our understanding of tipping behavior, we could:### Next Steps\n",
    "---\n",
    "\n",
    "### Enhanced Scatter Plot Analysis\n",
    "\n",
    "```python"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
